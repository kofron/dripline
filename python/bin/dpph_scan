#!/usr/bin/python
''' dpph_scan
Make a dpph based field measurement
'''

from __future__ import absolute_import

import numpy
from scipy import fftpack

import csv
import pika
import time

from dripline.core import DriplineParser, constants, Service, message, exceptions

import logging
logger = logging.getLogger('dpph_scan')

def scdb_log(broker, sensor, value_raw, value_cal=None, extra_memo=None, **kwargs):
    # construct log info
    to_log = {'from':sensor,
              'values':{'value_raw': value_raw,
                       'memo': 'logged manually',
                      },
             }
    if value_cal is not None:
        to_log['values']['value_cal'] = value_cal
    if extra_memo is not None:
        to_log['values']['memo'] += extra_memo
    logger.debug('logging to sensor: {}'.format(sensor))
    logger.debug('with info:\n{}'.format(to_log['values']))

    # make connection
    # note that we're not consuming, so the exchange and key values here don't really matter
    conn = Service(amqp_url = broker,exchange = 'alerts',keys = '#')
    conn.send_alert(severity='sensor_value', alert=to_log)
    logger.info('log sent')



def scdb_query(broker,sensor):
    request_verb = 'get'
    msgop = getattr(constants, 'OP_'+request_verb.upper())
    conn = Service(amqp_url = broker,
                   exchange = 'requests',
                   keys = '#'
                  )

    values = []
    payload = {}
    payload.update({'values':values})
    logger.debug('payload will be: {}'.format(payload))
    request = message.RequestMessage(msgop=msgop, payload=payload)
    try:
        reply = conn.send_request(sensor, request)
    except exceptions.DriplineException as dripline_error:
        logger.warning(dripline_error.message)
        return
    if not isinstance(reply, message.Message):
        result = message.Message.from_msgpack(reply)
    else:
        result = reply
    print_prefix = '->'.join([sensor])
    color = ''
    if not result.retcode == 0:
        color = '\033[91m'
    print('{color}{}: {}\033[0m'.format(print_prefix, result.payload, color=color))
    return result


def _get(name, connection):
    payload = {}
    payload.update({'values':[]})
    request = message.RequestMessage(msgop=constants.OP_GET,payload=payload)
    reply = connection.send_request(name, request)
    if not isinstance(reply, message.Message):
        result = message.Message.from_msgpack(reply)
    else:
        result = reply
    result_message = result.payload
    logger.debug("{}-> {}".format(name, result_message))
    return result_message


def get_data(connection):
    if not connection:
        logger.warning("no connection, can't get data")
        raise ValueError('no connection')
    data = {}
    # ensure lockin config
    logger.info('ensure_setup')
    _get('lockin_ensure_setup', connection)
    # trigger taking data
    result = _get('lockin_take_data', connection)
    # wait for data taking to finish
    while not result == 'done':
        time.sleep(0.2)
        result = _get('lockin_status', connection)
    # get data
    result = _get('lockin_mag_data', connection)
    data['amplitude'] = numpy.array(result.strip('\0').replace('\x00','').split(), dtype=float)
    result = _get('lockin_adc_data', connection)
    data['sweep_out'] = numpy.array(result.strip('\0').replace('\x00','').split(), dtype=float)
    # Save additional data
    result = _get('lockin_x_data', connection)
    data['lockin_x_data'] = numpy.array(result.strip('\0').replace('\x00','').split(), dtype=float)
    result = _get('lockin_y_data', connection)
    data['lockin_y_data'] = numpy.array(result.strip('\0').replace('\x00','').split(), dtype=float)


    return data


def WeinerFilter(freq_data, amp_data, width=False):
    if not width:
        base_width = 4
        if max(freq_data) < 30: # assume GHz
            width = base_width * 1e-3
        elif max(freq_data) < 30000: # assume MHz
            width = base_width * 1
        elif max(freq_data) < 30000000: # assume kHz
            width = base_width * 1e3
        else: # assume Hz
            width = base_width * 1e6
    data = zip(freq_data, amp_data)
    data.sort()
    f,v= zip(*data)
    frequencies = numpy.array(f, dtype=float)
    voltages = numpy.array(v, dtype=float)
    x1 = (frequencies - frequencies[0]) / width
    x2 = (frequencies - frequencies[-1]) / width
    gderiv1 = x1 * numpy.exp(-x1 * x1 / 2.)
    gderiv2 = x2 * numpy.exp(-x2 * x2 / 2.)
    target_signal = (gderiv1 + gderiv2)
    target_fft = fftpack.fft(target_signal)
    data_fft = fftpack.fft(voltages)
    data_fft[0] = 0
    filtered = fftpack.ifft(data_fft * target_fft)
    return {'freqs': frequencies,
            'result': abs(filtered),
            'target': target_signal
           }


def FrequencyToField(frequency):
    geff = 2.0036
    charge_over_mass = 1.758e11
    tesla = (4 * numpy.pi * 10**7 / (geff * charge_over_mass) * frequency)
    return tesla


def main(broker, frequency_limits, output, **kwargs):
    ##### Connect to slow controls
    logger.info('broker is: {}'.format(broker))
    try:
        connection = Service(amqp_url=broker, exchange='requests', keys = ['#'])
    except pika.exceptions.AMQPConnectionError:
        logger.error('unable to connect to broker')
        #return
        connection = False

    ##### confirm frequency limits
    logger.info('frequency limits are: {}'.format(frequency_limits))
    if not frequency_limits:
        pass
        # something to get them from the sweeper
        logger.warning('trying to get hf_start_freq, that name is hard coded for now')
        result = connection.send_request(target='hf_start_freq', request=message.RequestMessage(msgop=constants.OP_GET, payload={'values':{}}))
        start_freq = float(result['payload']['value_raw'])
        logger.info('got a start of: {}'.format(start_freq))
        logger.warning('trying to get hf_stop_freq, that name is hard coded for now')
        result = connection.send_request(target='hf_stop_freq', request=message.RequestMessage(msgop=constants.OP_GET, payload={'values':{}}))
        stop_freq = float(result['payload']['value_raw'])
        logger.info('got a stop of: {}'.format(stop_freq))
        #logger.warning("don't know how to get freq limits automatically")
    else:
        start_freq = min(map(float, frequency_limits))
        stop_freq = max(map(float, frequency_limits))
    
    ######## get lock-in data
    # get data
    logger.info('now get data from lockin')
    lockin_data = get_data(connection)
    # map adc values to frequencies
    logger.info('map sweep out to frequencies')
    m = (stop_freq - start_freq) / (10.)
    lockin_data['frequencies'] = start_freq + m * lockin_data['sweep_out']
    # pass data to filter
    logger.info('do optimal filter on output')
    filter_data = WeinerFilter(lockin_data['frequencies'], lockin_data['amplitude'])
    res_freq = filter_data['freqs'][filter_data['result']==filter_data['result'].max()]
    # save raw output to file if requested
    if output:
        output_file = open(output, 'w')
        csv_writer = csv.writer(output_file)
        csv_writer.writerow(['sweep_out',
                             'sweep_freqs',
                             'lockin_signal',
                             'lockin_x_data',
                             'lockin_y_data',
                             'filter_freqs',
                             'filter_target',
                             'filter_result',
                            ])
        csv_writer.writerows(zip(lockin_data['sweep_out'],
                                 lockin_data['frequencies'],
                                 lockin_data['amplitude'],
                                 lockin_data['lockin_x_data'],
                                 lockin_data['lockin_y_data'],
                                 filter_data['freqs'],
                                 filter_data['target'],
                                 filter_data['result'],
                                ))
        output_file.close()
    # make plot if requested
    # prompt user for approval to log if requested
    # print field result
    logger.info("compute field")
    field = FrequencyToField(filter_data['freqs'][filter_data['result']==filter_data['result'].max()])
    #print('value is: {}'.format(field))

    #########
    # Save the results to the database
    # First, save the Z position
    sensor = 'string_pot_resistance'
    result = scdb_query(broker=broker,sensor=sensor)
    scdb_log(broker=broker, sensor=sensor, value_raw=result.payload['value_raw'], value_cal=result.payload['value_cal'])
    # Then the dpph value
    scdb_log(broker=broker, sensor='dpph', value_raw=field[0], value_cal=field[0])
    #########
    # Print Results
    print('String Z Position = %0.02f ; Field = %f kG' % (result.payload['value_cal'],field))
    print('Resuls logged to database')


if __name__ == '__main__':
    scan_doc = '''
               dpph_scan performs a dpph scan and field estimate
               '''
    parser = DriplineParser(description=scan_doc,
                            extra_logger=logger,
                            amqp_broker=True,
                            tmux_support=True,
                            twitter_support=True,
                           )
    # an option for outputting raw data
    parser.add_argument('-o', '--output', default=False)
    # an option for outputting a grahic
    # an option for passing in the sweeper limits
    parser.add_argument('-f', '--frequency-limits', nargs=2, default=[])
    # an option to log the result (have this prompt the user first?)
    args = parser.parse_args()
    main(**vars(args))
